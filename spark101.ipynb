{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2443c27d",
   "metadata": {},
   "source": [
    "# Spark API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0451d68b",
   "metadata": {},
   "source": [
    "## Testing Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c17118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4c8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc2c77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/15 21:34:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "spark.range(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f1e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266c5966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/15 21:34:31 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import pyspark\n",
    "\n",
    "nprocs = multiprocessing.cpu_count()\n",
    "\n",
    "spark = (pyspark.sql.SparkSession.builder\n",
    " .master('local')\n",
    " .config('spark.jars.packages', 'mysql:mysql-connector-java:8.0.16')\n",
    " .config('spark.driver.memory', '4G')\n",
    " .config('spark.driver.cores', nprocs)\n",
    " .config('spark.sql.shuffle.partitions', nprocs)\n",
    " .appName('MySparkApplication')\n",
    " .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5075486d",
   "metadata": {},
   "source": [
    "## 1. Create a spark data frame that contains your favorite programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ec309",
   "metadata": {},
   "source": [
    "- a. The name of the column should be language\n",
    "- b. View the schema of the dataframe\n",
    "- c. Output the shape of the dataframe\n",
    "- d. Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2725a88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe with my favorite languages\n",
    "pandas_dataframe = pd.DataFrame({'Python', 'SQL', 'HTML', 'CSS', 'JavaScript', 'R', 'Markdown'}, columns = ['languages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4955d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Markdown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    languages\n",
       "0         SQL\n",
       "1      Python\n",
       "2           R\n",
       "3         CSS\n",
       "4  JavaScript\n",
       "5        HTML\n",
       "6    Markdown"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7a1bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[languages: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pandas dataframe to spark dataframe\n",
    "language = spark.createDataFrame(pandas_dataframe)\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b67fddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- languages: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Output schema of dataframe\n",
    "language.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "183ee125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| languages|\n",
      "+----------+\n",
      "|       SQL|\n",
      "|    Python|\n",
      "|         R|\n",
      "|       CSS|\n",
      "|JavaScript|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Viewing the top 5 records\n",
    "language.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5a303d",
   "metadata": {},
   "source": [
    "By default spark will show the first 20 rows, but we can specify how many we want by passing a number to .show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a073f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|summary|languages|\n",
      "+-------+---------+\n",
      "|  count|        7|\n",
      "|   mean|     null|\n",
      "| stddev|     null|\n",
      "|    min|      CSS|\n",
      "|    max|      SQL|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "language.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd635e86",
   "metadata": {},
   "source": [
    "## 2. Load the mpg dataset as a spark dataframe.\n",
    "### a. Create 1 column of output that contains a message like the one below, for each vehicle.\n",
    "            The 1999 audi a4 has a 4 cylinder engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd04fa94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c79b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a table with spark\n",
    "mpg.createOrReplaceTempView(\"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae012308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             summary|\n",
      "+--------------------+\n",
      "|The 1999 audi a4h...|\n",
      "|The 1999 audi a4h...|\n",
      "|The 2008 audi a4h...|\n",
      "|The 2008 audi a4h...|\n",
      "|The 1999 audi a4h...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "'''\n",
    "SELECT CONCAT(\"The \", year, \" \", manufacturer, \" \", model, \"has a \", cyl, \" cylinder engine.\") as summary\n",
    "FROM mpg\n",
    "'''\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4816cd",
   "metadata": {},
   "source": [
    "### b. Transform the `trans` column so that it only contains either `manual` or `auto`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc47b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-----------+\n",
      "|     trans|regexp_extract|regexp_replace|when + like|\n",
      "+----------+--------------+--------------+-----------+\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(av)|          auto|          auto|       auto|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(av)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(l4)|          auto|          auto|       auto|\n",
      "|  auto(l4)|          auto|          auto|       auto|\n",
      "+----------+--------------+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    'trans',\n",
    "    regexp_extract(\"trans\", r\"^(\\w+)\\(\", 1).alias(\"regexp_extract\"),\n",
    "    regexp_replace(\"trans\", r\"\\(.+$\", \"\").alias(\"regexp_replace\"),\n",
    "    when(\n",
    "        mpg.trans.like(\"auto%\"), \"auto\"\n",
    "    ).otherwise(\"manual\").alias(\"when + like\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f535a2ad",
   "metadata": {},
   "source": [
    "## 3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "### a. What percentage of observations are smokers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd94aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the tips dataset\n",
    "\n",
    "tips = spark.createDataFrame(data(\"tips\"))\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b4889f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|smoker|count|\n",
      "+------+-----+\n",
      "|    No|  151|\n",
      "|   Yes|   93|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy(\"smoker\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c798eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b93bb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------------+\n",
      "|smoker|count|            percent|\n",
      "+------+-----+-------------------+\n",
      "|    No|  151| 0.6188524590163934|\n",
      "|   Yes|   93|0.38114754098360654|\n",
      "+------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupby('smoker').count().withColumn('percent', col('count') / tips.count()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7240acbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+\n",
      "|smoker|count|percent|\n",
      "+------+-----+-------+\n",
      "|    No|  151|    62%|\n",
      "|   Yes|   93|    38%|\n",
      "+------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy(\"smoker\").count().withColumn(\n",
    "    \"percent\",\n",
    "    concat(round((col(\"count\") / tips.count() * 100), 0).cast(\"int\"), lit(\"%\")),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f798f3",
   "metadata": {},
   "source": [
    "### b. Create a column that contains the tip percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7cf0bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|     tip_percentage|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tips.withColumn(\"tip_percentage\", col('tip') / col('total_bill')).show()\n",
    "\n",
    "tips.withColumn(\"tip_percentage\", expr('tip / total_bill')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a39fe14",
   "metadata": {},
   "source": [
    "### c. Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4106414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|   sex|    No|   Yes|\n",
      "+------+------+------+\n",
      "|  Male|0.1607|0.1528|\n",
      "|Female|0.1569|0.1822|\n",
      "+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# method chaining - df.method1().method2()....\n",
    "(\n",
    "    tips.withColumn(\"tip_percentage\", col('tip') / col('total_bill'))\n",
    "    .groupby(\"sex\")\n",
    "    .pivot(\"smoker\") # make a pivot table\n",
    "    .agg(round(mean(\"tip_percentage\"), 4))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b031f215",
   "metadata": {},
   "source": [
    "## 4. Use the seattle weather dataset referenced in the lesson to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc5aa5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import Seattle weather dataset\n",
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather()\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7d9b8",
   "metadata": {},
   "source": [
    "### a. Convert the temperatures to fahrenheit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a5a3b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|   55.04|    41.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|   51.08|   37.04| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|   53.06|   44.96| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|   53.96|   42.08| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|   48.02|   37.04| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather = spark.createDataFrame(weather)\n",
    "weather = weather.withColumn(\n",
    "    \"temp_max\", (col(\"temp_max\") * 9 / 5 + 32)\n",
    ").withColumn(\"temp_min\", (col(\"temp_min\") * 9 / 5 + 32))\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ee67a",
   "metadata": {},
   "source": [
    "### b. Which month has the most rain, on average?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e10d93a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(month=11, avg_monthly_rain=160.625)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = (\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"month\", \"year\")\n",
    "    .agg(sum(\"precipitation\").alias(\"total_monthly_precipitation\"))\n",
    "    .groupBy(\"month\")\n",
    "    .agg(mean(\"total_monthly_precipitation\").alias(\"avg_monthly_rain\"))\n",
    "    .sort(col(\"avg_monthly_rain\").desc())\n",
    "    .first()\n",
    ")\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7b97cd",
   "metadata": {},
   "source": [
    "### c. Which year was the windiest?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c8c7793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2012, total_winds=1244.6999999999998),\n",
       " Row(year=2014, total_winds=1236.5),\n",
       " Row(year=2015, total_winds=1153.3),\n",
       " Row(year=2013, total_winds=1100.8000000000002)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    weather.withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"year\")\n",
    "    .agg(sum(\"wind\").alias(\"total_winds\"))\n",
    "    .sort(col(\"total_winds\").desc())\n",
    "    .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db4598b",
   "metadata": {},
   "source": [
    "### d. What is the most frequent type of weather in January?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0905805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "|   rain|   35|\n",
      "|    sun|   33|\n",
      "|drizzle|   10|\n",
      "|   snow|    8|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .filter(col(\"month\") == 1)\n",
    "    .groupBy(\"weather\")\n",
    "    .count()\n",
    "    .sort(col(\"count\").desc())\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "632f4858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|drizzle|   54|\n",
      "|   rain|  259|\n",
      "|    sun|  714|\n",
      "|   snow|   23|\n",
      "|    fog|  411|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# .value_counts for spark\n",
    "weather.groupBy('weather').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129fe489",
   "metadata": {},
   "source": [
    "### e. What is the average high and low temperature on sunny days in July in 2013 and 2014?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d00aba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|average_high_temp| average_low_temp|\n",
      "+-----------------+-----------------+\n",
      "|80.29192307692308|57.52884615384615|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.filter(month(\"date\") == 7)\n",
    "    .filter(year(\"date\") > 2012)\n",
    "    .filter(year(\"date\") < 2015)\n",
    "    .filter(col(\"weather\") == lit(\"sun\"))\n",
    "    .agg(\n",
    "        avg(\"temp_max\").alias(\"average_high_temp\"),\n",
    "        avg(\"temp_min\").alias(\"average_low_temp\"),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c842fe",
   "metadata": {},
   "source": [
    "### f. What percentage of days were rainy in q3 of 2015?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8e3d665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           avg(rain)|\n",
      "+--------------------+\n",
      "|0.021739130434782608|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.filter(year(\"date\") == 2015)\n",
    "    .filter(quarter(\"date\") == 3)\n",
    "    .select(when(col(\"weather\") == \"rain\", 1).otherwise(0).alias(\"rain\"))\n",
    "    .agg(mean(\"rain\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15ccef",
   "metadata": {},
   "source": [
    "### g. For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "890654aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|year|      avg(did_rain)|\n",
      "+----+-------------------+\n",
      "|2012|0.48360655737704916|\n",
      "|2013|0.41643835616438357|\n",
      "|2014|  0.410958904109589|\n",
      "|2015|0.39452054794520547|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# measure a rainy day by precipitation > 0\n",
    "(\n",
    "    weather.withColumn(\"year\", year(\"date\"))\n",
    "    .select(when(col(\"precipitation\") > 0, 1).otherwise(0).alias(\"did_rain\"), \"year\")\n",
    "    .groupby(\"year\")\n",
    "    .agg(mean(\"did_rain\"))\n",
    "    .show()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
